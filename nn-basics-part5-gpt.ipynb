{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e0c9ac",
   "metadata": {},
   "source": [
    "## Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f462b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel Green\n",
      "Well, can I keep the presents and still be 29?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from convokit import Corpus, download\n",
    "\n",
    "filename = \"~/.convokit/downloads/friends-corpus\"\n",
    "corpus = Corpus(filename=os.path.expanduser(filename))\n",
    "\n",
    "utterance = corpus.get_utterance('s07_e14_c01_u018')\n",
    "print(utterance.speaker.id)\n",
    "print(utterance.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ce4f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monica Geller\n",
      "There's nothing to tell! He's just some guy I work with!\n",
      "\n",
      "Joey Tribbiani\n",
      "C'mon, you're going out with the guy! There's gotta be something wrong with him!\n",
      "\n",
      "Chandler Bing\n",
      "All right Joey, be nice. So does he have a hump? A hump and a hairpiece?\n",
      "\n",
      "Phoebe Buffay\n",
      "Wait, does he eat chalk?\n",
      "\n",
      "Phoebe Buffay\n",
      "Just, 'cause, I don't want her to go through what I went through with Carl oh!\n",
      "\n",
      "Monica Geller\n",
      "Okay, everybody relax. This is not even a date. It's just two people going out to dinner and no\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "re_pattern = \"[^0-9a-zA-Z,.?!' ]\"\n",
    "\n",
    "all_utterance = []\n",
    "\n",
    "for utterance in corpus.iter_utterances():\n",
    "    speaker = utterance.speaker.id\n",
    "    if speaker == \"TRANSCRIPT_NOTE\":\n",
    "        # Only interested in conversations\n",
    "        continue\n",
    "    speaker = re.sub(re_pattern, '', speaker)\n",
    "    text = re.sub(re_pattern, '', utterance.text)\n",
    "    all_utterance.append(f\"{speaker}\\n{text}\")\n",
    "\n",
    "n = int(len(all_utterance) * 0.9)\n",
    "train_data_text = '\\n\\n'.join(all_utterance[:n])\n",
    "val_data_text = '\\n\\n'.join(all_utterance[n:])\n",
    "\n",
    "print(train_data_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5858461d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 69\n",
      "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, ',': 4, '.': 5, '0': 6, '1': 7, '2': 8, '3': 9, '4': 10, '5': 11, '6': 12, '7': 13, '8': 14, '9': 15, '?': 16, 'A': 17, 'B': 18, 'C': 19, 'D': 20, 'E': 21, 'F': 22, 'G': 23, 'H': 24, 'I': 25, 'J': 26, 'K': 27, 'L': 28, 'M': 29, 'N': 30, 'O': 31, 'P': 32, 'Q': 33, 'R': 34, 'S': 35, 'T': 36, 'U': 37, 'V': 38, 'W': 39, 'X': 40, 'Y': 41, 'Z': 42, 'a': 43, 'b': 44, 'c': 45, 'd': 46, 'e': 47, 'f': 48, 'g': 49, 'h': 50, 'i': 51, 'j': 52, 'k': 53, 'l': 54, 'm': 55, 'n': 56, 'o': 57, 'p': 58, 'q': 59, 'r': 60, 's': 61, 't': 62, 'u': 63, 'v': 64, 'w': 65, 'x': 66, 'y': 67, 'z': 68}\n"
     ]
    }
   ],
   "source": [
    "all_characters = sorted(list(set(train_data_text)))\n",
    "stoi = {s:i for i, s in enumerate(sorted(all_characters))}\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n",
    "print(\"Dictionary size:\", len(stoi))\n",
    "print(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d8b7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24, 47, 54, 54, 57,  1, 65, 57, 60, 54, 46])\n",
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "encode = lambda s: torch.tensor([stoi[c] for c in s])\n",
    "decode = lambda c: ''.join([itos[v.item()] for v in c])\n",
    "\n",
    "train_data = encode(train_data_text)\n",
    "val_data = encode(val_data_text)\n",
    "\n",
    "print(encode(\"Hello world\"))\n",
    "print(decode(encode(\"Hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf473b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([52, 43, 45, 53, 47, 62,  5,  0]) -> tensor([43, 45, 53, 47, 62,  5,  0,  0])\n",
      "\n",
      "tensor([52]) -> 43\n",
      "j -> a\n",
      "tensor([52, 43]) -> 45\n",
      "ja -> c\n",
      "tensor([52, 43, 45]) -> 53\n",
      "jac -> k\n",
      "tensor([52, 43, 45, 53]) -> 47\n",
      "jack -> e\n",
      "tensor([52, 43, 45, 53, 47]) -> 62\n",
      "jacke -> t\n",
      "tensor([52, 43, 45, 53, 47, 62]) -> 5\n",
      "jacket -> .\n",
      "tensor([52, 43, 45, 53, 47, 62,  5]) -> 0\n",
      "jacket. -> \n",
      "\n",
      "tensor([52, 43, 45, 53, 47, 62,  5,  0]) -> 0\n",
      "jacket.\n",
      " -> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(100)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        data = train_data\n",
    "    elif split == 'val':\n",
    "        data = val_data\n",
    "\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return (x, y)\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print(x[0], '->', y[0])\n",
    "print()\n",
    "for t in range(block_size):\n",
    "    print(f\"{x[0, :t+1]} -> {y[0, t]}\")\n",
    "    print(f\"{decode(x[0, :t+1])} -> {decode(y[0, t].view(-1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6fe530",
   "metadata": {},
   "source": [
    "# A simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "217898a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_emb, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_emb, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_emb),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7fb60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vocab = len(stoi)\n",
    "d_emb = 64\n",
    "d_ff = 128\n",
    "dropout = 0.1\n",
    "\n",
    "\n",
    "# v0.1\n",
    "class SimpleLanguageModel(nn.Module):\n",
    "    '''Simple Bigram language model with a single feedforward layer'''\n",
    "    def __init__(self, d_vocab, d_emb, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(d_vocab, d_emb)  # B, T -> B, T, d_emb\n",
    "        self.ffwd = FeedForward(d_emb, d_ff, dropout)  # B, T, d_emb -> B, T, d_emb\n",
    "        self.lm_head = nn.Linear(d_emb, d_vocab)  # B, T, d_emb -> B, T, d_vocab\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        # B, T = x.shape\n",
    "        x = self.emb(x) # B, T, d_emb\n",
    "        logits = self.lm_head(x) # B, T, d_vocab\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            B, T, d_vocab = logits.shape\n",
    "            logits = logits.view(-1, d_vocab)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, x, n_tokens):\n",
    "        # B, T = x.shape\n",
    "        for _ in range(n_tokens):\n",
    "            x_cond = x[:, -block_size:]\n",
    "            logits, loss = self(x_cond)  # logits: B, T, d_vocab\n",
    "            logits = logits[:, -1, :]  # B, d_vocab\n",
    "            probs = F.softmax(logits, dim=-1)  # B, d_vocab\n",
    "            x_next = torch.multinomial(probs, num_samples=1)  # B, 1\n",
    "            x = torch.cat((x, x_next), dim=1)  # B, T+1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ff65c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLanguageModel(d_vocab, d_emb, d_ff, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6d07a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 69])\n",
      "tensor(4.2338, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "xb, yb = xb[:1], yb[:1]\n",
    "logit, loss = model(xb, yb)\n",
    "print(logit.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "838b7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.2 - with the generate function\n",
    "class SimpleLanguageModel(nn.Module):\n",
    "    '''Simple Bigram language model with a single feedforward layer'''\n",
    "    def __init__(self, d_vocab, d_emb, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(d_vocab, d_emb)  # B, T -> B, T, d_emb\n",
    "        self.ffwd = FeedForward(d_emb, d_ff, dropout)  # B, T, d_emb -> B, T, d_emb\n",
    "        self.lm_head = nn.Linear(d_emb, d_vocab)  # B, T, d_emb -> B, T, d_vocab\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        # B, T = x.shape\n",
    "        x = self.emb(x) # B, T, d_emb\n",
    "        logits = self.lm_head(x) # B, T, d_vocab\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            B, T, d_vocab = logits.shape\n",
    "            logits = logits.view(-1, d_vocab)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, x, n_tokens):\n",
    "        # B, T = x.shape\n",
    "        for _ in range(n_tokens):\n",
    "            x_cond = x[:, -block_size:]\n",
    "            logits, loss = self(x_cond)  # logits: B, T, d_vocab\n",
    "            logits = logits[:, -1, :]  # B, d_vocab\n",
    "            probs = F.softmax(logits, dim=-1)  # B, d_vocab\n",
    "            x_next = torch.multinomial(probs, num_samples=1)  # B, 1\n",
    "            x = torch.cat((x, x_next), dim=1)  # B, T+1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17c32424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 62,  4, 66, 56, 65, 20, 29, 16, 43, 28,  0,  8, 50,  3, 55, 13, 65,\n",
      "         55,  7, 15, 61,  0, 47, 43, 52, 28, 15, 64, 57,  2, 14, 14,  6, 24, 61,\n",
      "         55, 56, 28,  3, 35, 31, 30, 21, 16, 56, 18, 49, 59, 38,  1,  7, 38, 16,\n",
      "         61,  5, 32, 25, 49,  6, 44, 27, 47, 35, 30, 59, 35,  4, 24,  9, 57, 64,\n",
      "         43, 66, 51, 10,  0, 28, 62, 24, 44, 65, 40, 37, 14, 67, 51, 63, 57, 56,\n",
      "         10, 65, 28, 42, 28, 54, 38, 65, 43, 24, 33]])\n",
      "\n",
      "t,xnwDM?aL\n",
      "2h'm7wm19s\n",
      "eajL9vo!880HsmnL'SONE?nBgqV 1V?s.PIg0bKeSNqS,H3ovaxi4\n",
      "LtHbwXU8yiuon4wLZLlVwaHQ\n"
     ]
    }
   ],
   "source": [
    "model = SimpleLanguageModel(d_vocab, d_emb, d_ff, dropout).to(device)\n",
    "gen_text = model.generate(x=torch.zeros((1, 1), dtype=torch.long), n_tokens=100)\n",
    "print(gen_text)\n",
    "print(decode(gen_text[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6260435",
   "metadata": {},
   "source": [
    "# Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "064d9d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.234402709007263"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters=200):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    for i in range(eval_iters):\n",
    "        x, y = get_batch('val')\n",
    "        logits, loss = model(x, y)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / eval_iters\n",
    "\n",
    "estimate_loss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d575624",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "817fff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.234487533569336\n",
      "Validation loss: 4.23272953748703\n",
      "5000 2.5389506816864014\n",
      "10000 2.267601728439331\n",
      "15000 2.421492338180542\n",
      "20000 2.291759490966797\n",
      "Validation loss: 2.3960675978660584\n",
      "25000 2.4318416118621826\n",
      "30000 2.4329137802124023\n",
      "35000 2.277162790298462\n",
      "40000 2.3940908908843994\n",
      "Validation loss: 2.405582616329193\n",
      "45000 2.512033462524414\n",
      "50000 2.228994607925415\n",
      "55000 2.5251286029815674\n",
      "60000 2.400392770767212\n",
      "Validation loss: 2.4019481694698332\n",
      "65000 2.4505093097686768\n",
      "70000 2.365840435028076\n",
      "75000 2.348484754562378\n",
      "80000 2.289278268814087\n",
      "Validation loss: 2.40008819937706\n",
      "85000 2.407731056213379\n",
      "90000 2.297285318374634\n",
      "95000 2.272923469543457\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % 5000 == 0:\n",
    "        print(steps, loss.item())\n",
    "        if steps % 20000 == 0:\n",
    "            print(\"Validation loss:\", estimate_loss(model))\n",
    "\n",
    "    # comment out after confirmed it works\n",
    "    # if steps >= 5000:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18868156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yotoey i\n",
      "Molkindoey, ss!\n",
      "Doni\n",
      "Weroe ks t benott'thig I't.\n",
      "\n",
      "\n",
      "Jous jut w, arseeel angh hate. Tars s te\n"
     ]
    }
   ],
   "source": [
    "# Generation\n",
    "print(decode(\n",
    "    model.generate(x=torch.zeros((1, 1), dtype=torch.long), n_tokens=100)[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842bb0b2",
   "metadata": {},
   "source": [
    "## Self attention\n",
    "\n",
    "Self attention is a communication mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bf4eab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values = \n",
      " tensor([[5., 8.],\n",
      "        [0., 5.],\n",
      "        [3., 4.]])\n",
      "----------\n",
      "first_k_avg = \n",
      " tensor([[5.0000, 8.0000],\n",
      "        [2.5000, 6.5000],\n",
      "        [2.6667, 5.6667]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(415)\n",
    "values = torch.randint(0, 10, (3, 2)).float()\n",
    "\n",
    "# Version 1: naive for-loop\n",
    "first_k_avg = torch.empty_like(values)\n",
    "for i in range(first_k_avg.shape[0]):\n",
    "    for j in range(first_k_avg.shape[1]):\n",
    "        first_k_avg[i, j] = values[:i + 1, j].mean()\n",
    "\n",
    "print(\"values = \\n\", values)\n",
    "print('-' * 10)\n",
    "print(\"first_k_avg = \\n\", first_k_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6de91d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei = \n",
      " tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "----------\n",
      "first_k_avg = \n",
      " tensor([[5.0000, 8.0000],\n",
      "        [2.5000, 6.5000],\n",
      "        [2.6667, 5.6667]])\n"
     ]
    }
   ],
   "source": [
    "# Version 2: mat mul\n",
    "num_rows = values.shape[0]\n",
    "wei = torch.tril(torch.ones(num_rows, num_rows))\n",
    "wei = wei / torch.sum(wei, 1, keepdim=True)\n",
    "print(\"wei = \\n\", wei)\n",
    "print('-' * 10)\n",
    "print(\"first_k_avg = \\n\", wei @ values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39ba4a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei before softmax:\n",
      " tensor([[0., -inf, -inf],\n",
      "        [0., 0., -inf],\n",
      "        [0., 0., 0.]])\n",
      "----------\n",
      "wei after softmax:\n",
      " tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "----------\n",
      "first_k_avg = \n",
      " tensor([[5.0000, 8.0000],\n",
      "        [2.5000, 6.5000],\n",
      "        [2.6667, 5.6667]])\n"
     ]
    }
   ],
   "source": [
    "# Version 3: softmax\n",
    "wei = torch.zeros((num_rows, num_rows))\n",
    "tril = torch.tril(torch.ones_like(wei))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "print(\"wei before softmax:\\n\", wei)\n",
    "print('-' * 10)\n",
    "wei = F.softmax(wei, dim=1)\n",
    "print(\"wei after softmax:\\n\", wei)\n",
    "print('-' * 10)\n",
    "print(\"first_k_avg = \\n\", wei @ values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df8e9b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei:\n",
      " tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4607, 0.5393, 0.0000, 0.0000],\n",
      "         [0.3991, 0.2089, 0.3920, 0.0000],\n",
      "         [0.2587, 0.2108, 0.2907, 0.2397]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4038, 0.5962, 0.0000, 0.0000],\n",
      "         [0.2823, 0.3892, 0.3285, 0.0000],\n",
      "         [0.2289, 0.2493, 0.2322, 0.2896]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3789, 0.6211, 0.0000, 0.0000],\n",
      "         [0.3268, 0.3199, 0.3533, 0.0000],\n",
      "         [0.1970, 0.2184, 0.2262, 0.3584]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4430, 0.5570, 0.0000, 0.0000],\n",
      "         [0.2956, 0.3503, 0.3541, 0.0000],\n",
      "         [0.2012, 0.2451, 0.2963, 0.2574]]], grad_fn=<SoftmaxBackward0>)\n",
      "----------\n",
      "weight vector for third prediction:\n",
      " tensor([0.3991, 0.2089, 0.3920, 0.0000], grad_fn=<SelectBackward0>)\n",
      "out shape: torch.Size([4, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "# Version 4: serlf attention\n",
    "\n",
    "B, T, C = 4, 4, 32  # batch, time, channels (embeddings)\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# Single head self attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x)  # (B, T, 16)\n",
    "q = query(x)  # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1) * C**-0.5  # (B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "print(\"wei:\\n\", wei)\n",
    "print('-' * 10)\n",
    "print(\"weight vector for third prediction:\\n\", wei[0, 2])\n",
    "print(\"out shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992aa172",
   "metadata": {},
   "source": [
    "## Notes on Key, Query, Value in self attention\n",
    "\n",
    "Attention is a communication mechanism. It works as a directed graph, passing information along some direction. In text generation, it often involves passing information from past tokens to future tokens.\n",
    "\n",
    "There are three components in self attention mechanism.\n",
    "* Query - Q(x) projects what information x is seeking\n",
    "* Key - K(x) projects what information x contains\n",
    "* Value - V(x) determines what information should be aggregated for the purpose of this single attention head\n",
    "\n",
    "To understand Q, K, V intuitively,\n",
    "* Think of x like private information or private key of a token, it is then projected into the Query, Key, and Value handled by the attention head.\n",
    "* The output of self attention is a weighted sum of the projection V(x), not the tokens themselves. Why?\n",
    "    * It enables us to simultaneously consider various aspects of tokens in different heads after we introduce multi-head attention mechanism next.\n",
    "    * For example, in processing the word \"cat\" within a sentence, different attention heads might aggregate information with regards to its grammatical role (noun), its conceptual meaning as an animal, or its syntactic function as a subject or object. This diversity allows for a richer, more nuanced understanding of text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a46805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    '''Single head self attention'''\n",
    "\n",
    "    def __init__(self, d_emb, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "        self.key = nn.Linear(d_emb, d_head, bias=False)\n",
    "        self.query = nn.Linear(d_emb, d_head, bias=False)\n",
    "        self.value = nn.Linear(d_emb, d_head, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: B, T, d_emb\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        wei = q @ k.transpose(-2, -1) * (self.d_head ** -0.5)\n",
    "        wei = wei.masked_fill(self.tril == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHead(nn.Module):\n",
    "    '''Multi head self attention'''\n",
    "\n",
    "    def __init__(self, num_heads, d_emb, d_head):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(d_emb, d_head) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(num_heads * d_head, d_emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: B, T, d_emb\n",
    "        head_out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(head_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af815e",
   "metadata": {},
   "source": [
    "## Final Notes on Attention Mechanism\n",
    "\n",
    "1. **Position Encoding**: Attention mechanisms inherently lack a notion of order, unlike convolutions. Therefore, inputs to the attention mechanism should include positional information to maintain sequence context.\n",
    "2. **Scaled Attention**: To prevent the softmax function from collapsing into a one-hot vector, it's crucial that the weights (Q @ K) are diffused appropriately, hence the need for scaling attention (divided by d_head**0.5).\n",
    "3. **Batch Isolation**: Examples within the same batch do not interact; each instance is processed independently.\n",
    "4. **Transformer Architecture Variations**:\n",
    "    - **Decoder Block**: Restricts information flow to prevent future tokens from influencing the output, typically used in output generation phases.\n",
    "    - **Encoder Block**: Allows free communication among all nodes, fully utilizing context, typically used in input interpretation phases.\n",
    "    - **Application in the Transformer paper**: In context of machine translation, the original paper uses Encoder Blocks for source language text, encoding full contextual understanding, and uses Decoder Blocks for target language text, ensuring generated content is influenced only by preceding text and the source content.\n",
    "\n",
    "In addition to self-attention, a transformer block comprises:\n",
    "\n",
    "- **Computation Layer**: a feedforward network computes over the aggregated information, but on per token basis (no communication between two tokens at this step)\n",
    "- **Optimization Techniques for Deep Networks**:\n",
    "    - **Residual Connection**: Facilitates learning by creating shortcuts for gradients, acting as a \"super-highway\" for backpropagation.\n",
    "    - **Layer Normalization**: Standardizes the inputs to each layer, ensuring consistent scale and aiding in stable training.\n",
    "    - **Dropout**: Randomly omits a subset of features at each layer to prevent overfitting and encourage generalized representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02b6dc",
   "metadata": {},
   "source": [
    "## Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e7183f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm1d:\n",
    "    '''Layer normalization over the last dimension'''\n",
    "\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # In batch norm, we aggregate over columns\n",
    "        # In layer norm, we aggregate over rows\n",
    "        xmean = x.mean(1, keepdim=True)\n",
    "        xvar = x.var(1, keepdim=True)\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c534accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    '''Transformer block with multi-head attention and feedforward'''\n",
    "\n",
    "    def __init__(self, n_emb, n_head):\n",
    "        super().__init__()\n",
    "        d_head = n_emb // n_head\n",
    "        self.attn = MultiHead(n_head, n_emb, d_head)\n",
    "        self.ffwd = FeedForward(n_emb, n_emb, dropout=0.1)\n",
    "        self.ln1 = LayerNorm1d(n_emb)\n",
    "        self.ln2 = LayerNorm1d(n_emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: B, T, n_emb\n",
    "        # with residual connection\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be931d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3 - with the transformer block\n",
    "class SimpleLanguageModelWithTransformer(nn.Module):\n",
    "    '''Simple Bigram language model with transformer layers'''\n",
    "    def __init__(self, d_vocab, d_emb, num_heads, n_layers):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(d_vocab, d_emb)  # B, T -> B, T, d_emb\n",
    "        self.position_emb = nn.Embedding(block_size, d_emb)  # B, T -> B, T, d_emb\n",
    "        # Note: Changed here\n",
    "        # self.ffwd = FeedForward(d_emb, d_ff, dropout)  # B, T, d_emb -> B, T, d_emb\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[TransformerBlock(d_emb, num_heads) for _ in range(n_layers)]\n",
    "        )\n",
    "        self.ln_final = LayerNorm1d(d_emb)\n",
    "        self.lm_head = nn.Linear(d_emb, d_vocab)  # B, T, d_emb -> B, T, d_vocab\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        _, T = x.shape\n",
    "        token_emb = self.token_emb(x) # B, T, d_emb\n",
    "        pos_emb = self.position_emb(torch.arange(T, device=device))\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_final(x)\n",
    "        logits = self.lm_head(x) # B, T, d_vocab\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            B, T, d_vocab = logits.shape\n",
    "            logits = logits.view(-1, d_vocab)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, x, n_tokens):\n",
    "        # B, T = x.shape\n",
    "        for _ in range(n_tokens):\n",
    "            x_cond = x[:, -block_size:]\n",
    "            logits, loss = self(x_cond)  # logits: B, T, d_vocab\n",
    "            logits = logits[:, -1, :]  # B, d_vocab\n",
    "            probs = F.softmax(logits, dim=-1)  # B, d_vocab\n",
    "            x_next = torch.multinomial(probs, num_samples=1)  # B, 1\n",
    "            x = torch.cat((x, x_next), dim=1)  # B, T+1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ca14a08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58949\n"
     ]
    }
   ],
   "source": [
    "n_layer = 2\n",
    "num_heads = 4\n",
    "model = SimpleLanguageModelWithTransformer(d_vocab, d_emb, num_heads, n_layer)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ccea345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.24773478507995605\n",
      "Validation loss: 0.30973424449563025\n",
      "5000 0.27425718307495117\n",
      "10000 0.21987920999526978\n",
      "15000 0.18086157739162445\n",
      "20000 0.21900688111782074\n",
      "Validation loss: 0.22092035230249166\n",
      "25000 0.15958018600940704\n",
      "30000 0.17139407992362976\n",
      "35000 0.19953906536102295\n",
      "40000 0.2372569739818573\n",
      "Validation loss: 0.22083871014416218\n",
      "45000 0.29703056812286377\n",
      "50000 0.2268242985010147\n",
      "55000 0.22745905816555023\n",
      "60000 0.18956774473190308\n",
      "Validation loss: 0.20059844925999643\n",
      "65000 0.18979783356189728\n",
      "70000 0.23059050738811493\n",
      "75000 0.1879863440990448\n",
      "80000 0.2020922303199768\n",
      "Validation loss: 0.20507150873541832\n",
      "85000 0.19734027981758118\n",
      "90000 0.18905195593833923\n",
      "95000 0.1357641965150833\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "batch_size = 32\n",
    "for steps in range(100000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % 5000 == 0:\n",
    "        print(steps, loss.item())\n",
    "        if steps % 20000 == 0:\n",
    "            print(\"Validation loss:\", estimate_loss(model))\n",
    "\n",
    "    # comment out after confirmed it works\n",
    "    # if steps >= 5000:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bbfb2da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2010563813149929\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loss:\", estimate_loss(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a5d83d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lod.?!\n",
      "\n",
      "Rossch\n",
      "Monica?\n",
      "\n",
      "Joey Tribbiani\n",
      "I do. Thanks.\n",
      "\n",
      "Ross Geller\n",
      "The but werk, man't my my ean that you're no..... No!ly you mose no printen!\n",
      "\n",
      "Chandler Binger.\n",
      "\n",
      "Rachel Green\n",
      "Uhhh?\n",
      "\n",
      "Pecae\n",
      "All right, sho?\n",
      "\n",
      "Monica Geller\n",
      "I and! ot on my the bot? It's not for juss so roundin' shote.\n",
      "\n",
      "Phoebe Buffay\n",
      "Ohho, Ross!!\n",
      "\n",
      "Ross Geller\n",
      "You long?\n",
      "\n",
      "Chandler Bing\n",
      "It's not?\n",
      "\n",
      "bode?\n",
      "\n",
      "Rachel Green\n",
      "All not.\n",
      "\n",
      "Ross Geller\n",
      "WhoI and at try?\n",
      "\n",
      "Rachel Green\n",
      "So han. Well II lies.\n",
      "\n",
      "Ross Geller\n",
      "Ross Geller\n",
      "Oat....\n",
      "\n",
      "Chandler Bing\n"
     ]
    }
   ],
   "source": [
    "# Generation\n",
    "print(decode(\n",
    "    model.generate(x=torch.zeros((1, 8), dtype=torch.long), n_tokens=500)[0][8:]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149908c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38054cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977df1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b21eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea01cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fb73946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out))\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "# Map the context characters to an embedding vector\n",
    "class Embedding:\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.weight = torch.randn((vocab_size, embedding_dim))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = self.weight[x]\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # moving average\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # forward pass\n",
    "        if self.training:\n",
    "            xmean = x.mean(dim=0, keepdim=True)\n",
    "            xvar = x.var(dim=0, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        # normalize input\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update moving average\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = self.momentum * xmean + (1 - self.momentum) * self.running_mean\n",
    "                self.running_var = self.momentum * xvar + (1 - self.momentum) * self.running_var\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "820c3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5227ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fc874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c814a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "576d9b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a4ecf280>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(\n",
    "    # lossi\n",
    "    torch.tensor(lossi).view(-1, 100).mean(dim=1).flatten().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f25ec",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68075e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb08f37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6969759464263916, 1.6934974193572998)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluation(X, Y):\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        loss = F.cross_entropy(logits, Y)\n",
    "    return loss.item()\n",
    "\n",
    "evaluation(Xtr, Ytr), evaluation(Xval, Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa4ce3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh my God! That's like ontease 'it.\n",
      "Oh I can't lot not gonna does loterder the get this is of. We at's to you meor, but wascryes it.\n",
      "What I do the ins. well yours.\n",
      "I may a secfirthe'd that's not gonna know......I'd Bo to Stein.\n",
      "Oh homall bigbit?\n",
      "In tish.\n",
      "Reastand then insiar, everying the preet?\n",
      "I knay, hey, she ganss stumpreanding in out 1 be some.\n",
      "This nowonow.!\n",
      "Why cine ume.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        X = torch.tensor([context]) # (1, block_size)\n",
    "        with torch.no_grad():\n",
    "            logits = model(X)\n",
    "            prob = F.softmax(logits, dim=1)\n",
    "            ix = torch.multinomial(prob, num_samples=1).item()\n",
    "        context = context[1:] + [ix]\n",
    "        if ix == 0:\n",
    "            break\n",
    "        out.append(ix)\n",
    "    print(''.join([itos[i] for i in out]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
